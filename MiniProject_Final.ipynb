{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emotion as emo\n",
    "import nltk\n",
    "import MPTs as MT\n",
    "import os\n",
    "import glob\n",
    "os.chdir(\"news_articles\")\n",
    "folders = glob.glob(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fileopener(foldernames) :\n",
    "    articles = {}\n",
    "    dates = {}\n",
    "    txt3 = ''\n",
    "    for x in foldernames : #폴더 열기\n",
    "        os.chdir(x)\n",
    "        files = glob.glob(\"*.txt\")\n",
    "        for f in files : #파일열기\n",
    "            f = open(f, \"r\")\n",
    "            txt = f.read()\n",
    "            f.close() #파일열기 끝\n",
    "            txt1 = txt.split(\"\\n\")\n",
    "            while '' in txt1 :\n",
    "                txt1.remove('')\n",
    "            #txt2.extend(txt1) #제목과 내용 분리를 위한 사전작업\n",
    "            for s in txt1[2:] :\n",
    "                txt3 += s\n",
    "            articles[txt1[1]] = txt3\n",
    "            #txt2 = []\n",
    "            txt3 = ''\n",
    "        dates[x] = articles #딕셔너리안에 딕셔너리 작업\n",
    "        articles = {}\n",
    "        os.chdir(\"..\")\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = fileopener(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['The year of the Latinos: Hispanic voting surge shaking up presidential election', 'Long lines, technical glitches greet some voters across the country', 'LA county elections boss criticized amid voter fraud claims', 'Meet Darren Soto, poised to make history as first Florida Puerto Rican in Congress', 'Latinos still far from the White House but could make history on down-ballot races this year', 'The Halftime Report endorsementThe polling place on the North Fork of Short Creek in Ohio County, W.Va. was a fine place to cast a ballot. It was a 100-year-old Methodist church with groaning floorboards that announced your arrival for the poll workers before you were halfway across the floor.', \"What to watch for in Tuesday's tight race for Senate control\", \"'Sleeping Giant' awake and roaring ? early voting shows high Latino turnout\", 'In battleground North Carolina, 2016 races too close to call.', \"Dying Florida man's family fights to get vote counted\", 'Trump, Clinton make final pitches as early votes counted in tiny New Hampshire towns', \"Krauthammer on Trump's role in the GOP if he loses election: 'He will be the power broker'\", 'Trump wins presidency, defeats Clinton in historic election upset', 'Maine Gov. LePage accused of voter intimidation', 'Organizers of Latino get-out-the-vote wait to see if their efforts paid off', 'Super PAC hoping Amish voters will make election day a GOP barn raiser', 'In battleground North Carolina, 2016 races too close to call'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"fox161107\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for x in file[\"cnn161107\"].keys() :\n",
    "    print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['World leaders welcome Trump presidential victory with mixed reactions', 'Canadian immigration website crashes during election', \"How two polls predicted Trump's surprise victory\", \"Trump's presidential victory sparks protests and vigils across the U.S.\", 'Trump wins presidency, overriding high Latino turnout fueled by effort to defeat him', \"Nevada's Cortez Masto becomes 1st Latina elected to the U.S. Senate\", 'Latino leaders see complicated picture in Hispanic election turnout and support', 'Voting glitches, long lines and machine break downs ? but no major problems'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"fox161109\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cnn161107', 'cnn161109', 'fox161107', 'fox161109'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize and prinout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords # remove words that just contain no meaning\n",
    "import sentiment_mod as s\n",
    "pattern= r'''[a-z]*.'''\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\".\")\n",
    "stop_words.add(\",\")\n",
    "stop_words.add(\"~!@#$%^&*()_+-=`{}[]|\\\\:;\\\"',./<>?-()\\\"\")\n",
    "\n",
    "\n",
    "#tokens = word_tokenize(string)\n",
    "\n",
    "#filtered_sentence = [w for w in tokens if not w in stop_words] #이 부분은 무엇인지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenwswords(sent) :\n",
    "    sym = \"’“”``''``''~!@#$%^&*()_--+-=`{}[]|\\\\:;\\\"',./<>?-()\\\"\"\n",
    "    token = word_tokenize(sent)\n",
    "    ftoken = [w for w in token if not w in stop_words]\n",
    "    for x in ftoken :\n",
    "        if x in sym :\n",
    "            ftoken.remove(x)\n",
    "    return ftoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"output.txt\", \"w\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freqprintout(dict) :\n",
    "    dia = {}\n",
    "    dic = {}\n",
    "    for x in dict.keys() :\n",
    "        for (k, v) in dict[x].items() :\n",
    "            for i in tokenwswords(k):\n",
    "                if i not in dia:\n",
    "                    dia[i] = 1\n",
    "                else:\n",
    "                    dia[i] += 1\n",
    "            for o in tokenwswords(v):\n",
    "                if o not in dic:\n",
    "                    dic[o] = 1\n",
    "                else:\n",
    "                    dic[o] += 1\n",
    "        f = open(\"output.txt\", \"a\", encoding = \"utf-8\")\n",
    "        f.write(\"word Frequency analysis, company name and the date : \" + x + \"\\n\\n\")\n",
    "        f.write(\"article Freq dict : \\n\")\n",
    "        for x in sorted(dia, key=dia.get, reverse=True)[:30]:\n",
    "            f.write(str(x) + \" \" +  str(dia[x]) + '\\n')\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"content Freq dict : \\n\")\n",
    "        for x in sorted(dic, key=dic.get, reverse=True)[:200]:\n",
    "            f.write(str(x) + \" \" +  str(dic[x]) + '\\n')\n",
    "        f.write(\"\\n\")\n",
    "        f.close()\n",
    "        dia = {}\n",
    "        dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqprintout(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentprintout(dict) :\n",
    "    for x in dict.keys() :\n",
    "        f = open(\"output.txt\", \"a\", encoding = \"utf-8\")\n",
    "        f.write(\"sentimental analysis, company name and the date : \" + x + \"\\n\\n\")\n",
    "        for (k, v) in dict[x].items() :\n",
    "            a_s = s.sentiment(k)\n",
    "            c_s = s.sentiment(v)\n",
    "            f.write(\"article name : \" + str(k) + \" result : \" + str(a_s) + '\\n')\n",
    "            f.write(\"content analysis result : \" + str(c_s) + \"\\n\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentprintout(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trump_word(dict) : \n",
    "    trumptoken = []\n",
    "    ex = []\n",
    "    sym = \"’“”``''``''~!@#$%^&*()_--+-=`{}[]|\\\\:;\\\"',./<>?-()\\\"\"\n",
    "    for (k, v) in dict.items() :\n",
    "        txta = tokenwswords(k)\n",
    "        txt = tokenwswords(v)\n",
    "        for i in range(len(txta)) :\n",
    "            if txta[i].lower() == \"trump\" :\n",
    "                trumptoken.extend(txta[i-4:i+5])\n",
    "        for i in range(len(txt)) :\n",
    "            if txt[i].lower() == \"trump\" :\n",
    "                trumptoken.extend(txt[i-4:i+5])\n",
    "    ftoken = [w for w in trumptoken if not w in stop_words]\n",
    "    for x in ftoken :\n",
    "        if x in sym :\n",
    "            ftoken.remove(x)\n",
    "    for x in ftoken :\n",
    "        if x.lower() == \"trump\" :\n",
    "            ftoken.remove(x)\n",
    "    return ftoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_trump_word_1607(dict) :\n",
    "    help = []\n",
    "    name = [\"cnn161107\"]\n",
    "    for x in name :\n",
    "        txt = trump_word(file[x])\n",
    "        help.extend(txt)\n",
    "    return help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_trump_word_1609(dict) :\n",
    "    help = []\n",
    "    name = [\"cnn161109\"]\n",
    "    for x in name :\n",
    "        txt = trump_word(file[x])\n",
    "        help.extend(txt)\n",
    "    return help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fox_trump_word_1607(dict) :\n",
    "    help = []\n",
    "    name = [\"fox161107\"]\n",
    "    for x in name :\n",
    "        txt = trump_word(file[x])\n",
    "        help.extend(txt)\n",
    "    return help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fox_trump_word_1609(dict) :\n",
    "    help = []\n",
    "    name = [\"fox161109\"]\n",
    "    for x in name :\n",
    "        txt = trump_word(file[x])\n",
    "        help.extend(txt)\n",
    "    return help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trump_sent(dict) : \n",
    "    trumptoken = []\n",
    "    ex = []\n",
    "    end = \".!?\"\n",
    "    sym = \"’“”``''``''~!@#$%^&*()_--+-=`{}[]|\\\\:;\\\"',./<>?-()\\\"\"\n",
    "    for x in dict.keys() :\n",
    "        for (k, v) in dict[x].items() :\n",
    "            if \"trump\" or \"Trump\" in k :\n",
    "                trumptoken.append(k)\n",
    "            txt = v.split(\".\" or \"!\" or \"?\")\n",
    "            for i in range(len(txt)) :\n",
    "                if \"trump\" or \"Trump\" in txt[i] :\n",
    "                    trumptoken.append(txt[i])\n",
    "    return trumptoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def senttrump(dict) :\n",
    "    ctw7 = cnn_trump_word_1607(dict)\n",
    "    ctw9 = cnn_trump_word_1609(dict)\n",
    "    ftw7 = fox_trump_word_1607(dict)\n",
    "    ftw9= fox_trump_word_1609(dict)\n",
    "    txt = ''\n",
    "    for x in ctw7 :\n",
    "        txt += x + ' '\n",
    "    f = open(\"output.txt\", \"a\", encoding = \"utf-8\")\n",
    "    f.write(\"cnn trump word sentiment analysis 161107: \" + str(s.sentiment(txt)) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    txt = ''\n",
    "    for x in ctw9 :\n",
    "        txt += x + ' '\n",
    "    f = open(\"output.txt\", \"a\", encoding = \"utf-8\")\n",
    "    f.write(\"cnn trump word sentiment analysis 161109: \" + str(s.sentiment(txt)) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    txt = ''\n",
    "    for x in ftw7 :\n",
    "        txt += x + ' '\n",
    "    f = open(\"output.txt\", \"a\", encoding = \"utf-8\")\n",
    "    f.write(\"fox trump word sentiment analysis 161107: \" + str(s.sentiment(txt)) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    for x in ftw9 :\n",
    "        txt += x + ' '\n",
    "    f = open(\"output.txt\", \"a\", encoding = \"utf-8\")\n",
    "    f.write(\"fox trump word sentiment analysis 161109: \" + str(s.sentiment(txt)) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senttrump(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
